{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import decisiontrees as dt\n",
    "import randomforest as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"toxicity-2/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to, using the confusion matrix values, calculate various metrics\n",
    "def GetAccuracy(tp, fp, tn, fn):\n",
    "    tot = tp+fp+tn+fn\n",
    "    truevals = tp+tn\n",
    "    acc = float(truevals) / float(tot)\n",
    "    return acc\n",
    "\n",
    "def GetPrecision(tp, fp, tn, fn):\n",
    "    pos = float(tp + fp)\n",
    "    return float(tp) / pos\n",
    "\n",
    "def GetRecall(tp, fp, tn, fn):\n",
    "    pos = float(tp + fn)\n",
    "    return float(tp) / pos\n",
    "\n",
    "def GetF1Score(tp, fp, tn, fn):\n",
    "    prec = GetPrecision(tp, fp, tn, fn)\n",
    "    rec = GetRecall(tp, fp, tn, fn)\n",
    "    numer = 2.0 * prec * rec\n",
    "    denom = prec + rec\n",
    "    return numer / denom\n",
    "\n",
    "def PrintMetrics(tp, fp, tn, fn, name = \"Unnamed Model\"):\n",
    "    \"\"\" \n",
    "    PrintMetrics() will call all the smaller functions to calculate the\n",
    "    metrics and print them in a neatly formatted way. You need to give\n",
    "    it all the metrics in order, and you can also give it the model name\n",
    "    (optional, set default to 'Unnamed Model')\n",
    "    \"\"\"\n",
    "    print(\"Accuracy of \" + name + \": \" + str(GetAccuracy(tp, fp, tn, fn)))\n",
    "    print(\"Precision of \" + name + \": \" + str(GetPrecision(tp, fp, tn, fn)))\n",
    "    print(\"Recall of \" + name + \": \" + str(GetRecall(tp, fp, tn, fn)))\n",
    "    print(\"F1-Score of \" + name + \": \" + str(GetF1Score(tp, fp, tn, fn)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training/testing dataset\n",
    "#this function is specific to the toxicity dataset, and it will split to have\n",
    "#the same fraction of both types in training/testing\n",
    "def TrainTestSplit(data, frac = 0.7):\n",
    "    \"\"\" \n",
    "    TrainTestSplit() takes a pandas dataframe and an optional fraction value\n",
    "    set to a default 0.7. It returns a training set that is the fraction parameter\n",
    "    proportion of the dataset, and a testing set that is the 1-fraction of the\n",
    "    dataset.\n",
    "\n",
    "    In this case, it will also split to ensure that an equal proportion of the\n",
    "    outcome variable, preset to \"Class\" here, is in both sets.\n",
    "    \"\"\"\n",
    "\n",
    "    df_toxic = data[data[\"Class\"] == \"Toxic\"]\n",
    "    df_nontoxic = data[data[\"Class\"] == \"NonToxic\"]\n",
    "    len_tox = len(df_toxic)\n",
    "    len_non = len(df_nontoxic)\n",
    "    tot = len(data)\n",
    "\n",
    "    train_indices_nontox = GetRandomIndices(n = int(frac * len_non), max = len_non)\n",
    "    train_indices_tox = GetRandomIndices(n = int(frac * len_tox), max = len_tox)\n",
    "    test_indices_nontox = GetRemainingIndices(train_indices_nontox, len_non)\n",
    "    test_indices_tox = GetRemainingIndices(train_indices_tox, len_tox)\n",
    "    \n",
    "    train_nontox = df_nontoxic.iloc[train_indices_nontox]\n",
    "    train_tox = df_toxic.iloc[train_indices_tox]\n",
    "    test_nontox = df_nontoxic.iloc[test_indices_nontox]\n",
    "    test_tox = df_toxic.iloc[test_indices_tox]\n",
    "    \n",
    "    train = pd.concat([train_nontox, train_tox])\n",
    "    test = pd.concat([test_nontox, test_tox])\n",
    "\n",
    "    return train, test\n",
    "\n",
    "#helper function: get random indices\n",
    "def GetRandomIndices(n, max, min = 0):\n",
    "    \"\"\" \n",
    "    GetRandomIndices() is a function that takes three integers:\n",
    "    - n, number of indices to draw\n",
    "    - max, maximum exclusive value to draw\n",
    "    - min, minimum inclusive value to draw (optional, default 0)\n",
    "    It returns a list of random indices from the specified range; this\n",
    "    list is guaranteed to have no repeats.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    while len(indices) < n:\n",
    "        current_num = np.random.randint(low = min, high = max)\n",
    "    \n",
    "        #check if exist\n",
    "        e = False\n",
    "        for j in range(len(indices)):\n",
    "            if current_num == indices[j]:\n",
    "                e = True\n",
    "\n",
    "        if e != True: \n",
    "            indices.append(current_num)\n",
    "\n",
    "    return indices\n",
    "\n",
    "#second helper functions: get the indices we did NOT pick\n",
    "def GetRemainingIndices(picked, max):\n",
    "    \"\"\" \n",
    "    For any list given as the first argument and the maximum value\n",
    "    given in the second, GetRemainingIndices() will return a list of\n",
    "    the values less than the maximum not in the parameter list.\n",
    "    \"\"\"\n",
    "    rem_indices = []\n",
    "    for i in range(max):\n",
    "        e = False\n",
    "        for j in picked:\n",
    "            if i == j:\n",
    "                e = True\n",
    "        if e != True:\n",
    "            rem_indices.append(i)\n",
    "\n",
    "    return rem_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for crossvalidation\n",
    "def MakeKFolds(data, k = 5):\n",
    "    \"\"\" \n",
    "    MakeKFolds() takes in a pandas dataframe and an integer k (default 5), and\n",
    "    returns a list of pandas dataframes that is k long.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    n_sub = int(n / k)\n",
    "    inds = GetRandomIndices(n, max = n)\n",
    "\n",
    "    folds = []\n",
    "    for i in range(k):\n",
    "        startind = i * n_sub\n",
    "        endind = (i + 1) * n_sub\n",
    "        current_indices = inds[startind:endind]\n",
    "        current_fold = data.iloc[current_indices]\n",
    "        folds.append(current_fold)\n",
    "\n",
    "    return folds\n",
    "\n",
    "def TrainValidationSplit(folds):\n",
    "    \"\"\" \n",
    "    TrainValidationSplit() takes the folds given from MakeKFolds() and randomly\n",
    "    assigns one fold to be a validation set and combines the others to make\n",
    "    the training set.\n",
    "    \"\"\"\n",
    "    k = len(folds)\n",
    "    fold_indices = []\n",
    "    for i in range(k):\n",
    "        fold_indices.append(i)\n",
    "\n",
    "    val_index = np.random.randint(k)\n",
    "    validation = folds[val_index]\n",
    "    train_indices = GetRemainingIndices([val_index], k)\n",
    "    \n",
    "    train = pd.DataFrame()\n",
    "    for j in train_indices:\n",
    "        train = pd.concat([train, folds[j]])\n",
    "\n",
    "    return train, validation\n",
    "\n",
    "def TuneTree(folds, grid):\n",
    "    \"\"\" \n",
    "    TuneTree() takes in datafolds and a tuning grid, made by MakeKFolds() and\n",
    "    dt.MakeTuningGrid(). It returns the parameters found in the grid that yielded\n",
    "    the best accuracy.\n",
    "    \"\"\"\n",
    "    k = len(grid)\n",
    "    accuracies = []\n",
    "    for i in range(k):\n",
    "        current_params = grid[i]\n",
    "        current_train, current_val = TrainValidationSplit(folds)\n",
    "\n",
    "        #a little QOL addition\n",
    "        #checks if we have more depth than variables\n",
    "        dep = 0\n",
    "        cols = len(current_train.columns)\n",
    "        if cols < current_params[2]:\n",
    "            dep = cols\n",
    "        else:\n",
    "            dep = current_params[2]\n",
    "\n",
    "        root = dt.MakeNode(current_train, 1)\n",
    "        tree = dt.BuildTree(root, current_train, 0, \n",
    "                            min=current_params[0], frac = current_params[1],\n",
    "                            maxDepth=dep)\n",
    "        preds = dt.Predict(tree, current_val)\n",
    "        tp, fp, tn, fn = dt.GetConfusionMatrix(current_val, preds)\n",
    "        \n",
    "        current_acc = GetAccuracy(tp, fp, tn, fn)\n",
    "        accuracies.append(current_acc)\n",
    "\n",
    "    max_index = np.argmax(np.array(accuracies))\n",
    "    return grid[max_index]\n",
    "\n",
    "def TuneForest(folds, grid):\n",
    "    \"\"\" \n",
    "    TuneForest() takes in datafolds and a tuning grid, made by MakeKFolds() and\n",
    "    rf.MakeTuningGrid(). It returns the parameters found in the grid that yielded\n",
    "    the best accuracy.\n",
    "    \"\"\"\n",
    "    k = len(grid)\n",
    "    accuracies = []\n",
    "    for i in range(k):\n",
    "        current_params = grid[i]\n",
    "        current_train, current_val = TrainValidationSplit(folds)\n",
    "\n",
    "        #a little QOL addition\n",
    "        #checks if we have more depth than variables\n",
    "        dep = 0\n",
    "        cols = len(current_train.columns)\n",
    "        if cols < current_params[2]:\n",
    "            dep = cols - 1\n",
    "        else:\n",
    "            dep = current_params[2]\n",
    "\n",
    "        f = rf.BuildRandomForest(current_train, trees = current_params[4], \n",
    "                                 subset_frac = current_params[3], min = current_params[0],\n",
    "                                 frac = current_params[1], maxDepth = dep)\n",
    "        preds = rf.ForestPredict(f, current_val)\n",
    "        tp, fp, tn, fn = dt.GetConfusionMatrix(current_val, preds)\n",
    "        \n",
    "        current_acc = GetAccuracy(tp, fp, tn, fn)\n",
    "        accuracies.append(current_acc)\n",
    "\n",
    "    max_index = np.argmax(np.array(accuracies))\n",
    "    return grid[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save parameters as a file\n",
    "#so you can build the trees again.\n",
    "def SaveParams(params, filename = \"params.txt\"):\n",
    "    with open(filename, \"w\") as fw:\n",
    "        for p in params:\n",
    "            fw.write(str(p))\n",
    "            fw.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree: 0.7115384615384616\n",
      "Precision of Decision Tree: 0.4117647058823529\n",
      "Recall of Decision Tree: 0.5833333333333334\n",
      "F1-Score of Decision Tree: 0.4827586206896552\n"
     ]
    }
   ],
   "source": [
    "#workflow for doing Decision Trees\n",
    "#MODIFY THIS - TRY TO NOT MODIFY FUNCTIONS\n",
    "train, test = TrainTestSplit(df)\n",
    "folds = MakeKFolds(train)\n",
    "g = dt.MakeTuningGrid(min_max = 10, frac_min = 0.7)\n",
    "best_params = TuneTree(folds, g)\n",
    "SaveParams(best_params, \"params_dt_full.txt\")\n",
    "final_root = dt.MakeNode(train, 1)\n",
    "final_tree = dt.BuildTree(final_root, train, 0, min = best_params[0],\n",
    "                          frac = best_params[1], maxDepth = best_params[2])\n",
    "preds = dt.Predict(final_tree, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, \"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree: 0.6923076923076923\n",
      "Precision of Decision Tree: 0.4117647058823529\n",
      "Recall of Decision Tree: 0.5384615384615384\n",
      "F1-Score of Decision Tree: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "#decision tree workflow\n",
    "#using default parameters\n",
    "root = dt.MakeNode(train, 1)\n",
    "tree = dt.BuildTree(root, train, 0, maxDepth=10)\n",
    "preds = dt.Predict(tree, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, name = \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list_paper = [\"MDEC-23\", \"MATS2v\", \"ATSC8s\", \"VE3_Dt\", \"CrippenMR\", \"SpMax7_Bhe\", \n",
    "              \"SpMin1_Bhs\", \"C1SP2\", \"GATS8e\", \"SpMax5_Bhv\", \"VE3_Dzi\", \"VPC-4\", \"Class\"]\n",
    "class_list_gb = [\"MDEC-23\", \"GATS8s\", \"VE3_Dzi\", \"CrippenMR\", \"VPC-4\", \"GATS8e\",\n",
    "                   \"ATSC8s\", \"C1SP2\", \"SpMax5_Bhv\", \"MATS2v\", \"SpMax7_Bhe\", \"SpMin1_Bhs\", \n",
    "                   \"VE3_Dt\", \"Class\"]\n",
    "df_paper_select = df[class_list_paper]\n",
    "df_gb_select = df[class_list_gb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree with Paper Selected Features: 0.6538461538461539\n",
      "Precision of Decision Tree with Paper Selected Features: 0.5294117647058824\n",
      "Recall of Decision Tree with Paper Selected Features: 0.47368421052631576\n",
      "F1-Score of Decision Tree with Paper Selected Features: 0.5\n"
     ]
    }
   ],
   "source": [
    "#workflow for doing Decision Trees\n",
    "#MODIFY THIS - TRY TO NOT MODIFY FUNCTIONS\n",
    "#this time, it is with modified features from paper\n",
    "train, test = TrainTestSplit(df_paper_select)\n",
    "folds = MakeKFolds(train)\n",
    "g = dt.MakeTuningGrid(min_max = 10, frac_min = 0.7, depth_min=5, depth_max=10)\n",
    "best_params = TuneTree(folds, g)\n",
    "SaveParams(best_params, \"params_dt_pap.txt\")\n",
    "final_root = dt.MakeNode(train, 1)\n",
    "final_tree_pap = dt.BuildTree(final_root, train, 0, min = best_params[0],\n",
    "                          frac = best_params[1], maxDepth = best_params[2])\n",
    "preds = dt.Predict(final_tree_pap, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, \"Decision Tree with Paper Selected Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree with Gradient Boost Selected Features: 0.6730769230769231\n",
      "Precision of Decision Tree with Gradient Boost Selected Features: 0.23529411764705882\n",
      "Recall of Decision Tree with Gradient Boost Selected Features: 0.5\n",
      "F1-Score of Decision Tree with Gradient Boost Selected Features: 0.31999999999999995\n"
     ]
    }
   ],
   "source": [
    "#workflow for doing Decision Trees\n",
    "#MODIFY THIS - TRY TO NOT MODIFY FUNCTIONS\n",
    "#this time, it is with modified features from Gradient Boost selection\n",
    "train, test = TrainTestSplit(df_gb_select)\n",
    "folds = MakeKFolds(train)\n",
    "g = dt.MakeTuningGrid(min_max = 10, frac_min = 0.7, depth_min=5, depth_max=10)\n",
    "best_params = TuneTree(folds, g)\n",
    "SaveParams(best_params, \"params_dt_gb.txt\")\n",
    "final_root = dt.MakeNode(train, 1)\n",
    "final_tree_gb = dt.BuildTree(final_root, train, 0, min = best_params[0],\n",
    "                          frac = best_params[1], maxDepth = best_params[2])\n",
    "preds = dt.Predict(final_tree_gb, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, \"Decision Tree with Gradient Boost Selected Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with Paper Selected Features: 0.6730769230769231\n",
      "Precision of Random Forest with Paper Selected Features: 0.23529411764705882\n",
      "Recall of Random Forest with Paper Selected Features: 0.5\n",
      "F1-Score of Random Forest with Paper Selected Features: 0.31999999999999995\n"
     ]
    }
   ],
   "source": [
    "#workflow for doing Random Forest\n",
    "#MODIFY THIS - TRY TO NOT MODIFY FUNCTIONS\n",
    "#we are trying this with the modified feature list from paper\n",
    "train, test = TrainTestSplit(df_paper_select)\n",
    "folds = MakeKFolds(train)\n",
    "g = rf.MakeTuningGrid(min_max = 10, frac_min = 0.7, depth_min=4, depth_max=8, n = 100, subs_min=0.7, subs_max=0.9)\n",
    "best_params = TuneForest(folds, g)\n",
    "SaveParams(best_params, \"params_rf_pap.txt\")\n",
    "final_root = dt.MakeNode(train, 1)\n",
    "final_forest_pap = rf.BuildRandomForest(train, trees = best_params[4], \n",
    "                                 subset_frac = best_params[3], min = best_params[0],\n",
    "                                 frac = best_params[1], maxDepth = best_params[2])\n",
    "preds_pap = rf.ForestPredict(final_forest_pap, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, \"Random Forest with Paper Selected Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with Gradient Boost Selected Features: 0.6730769230769231\n",
      "Precision of Random Forest with Gradient Boost Selected Features: 0.23529411764705882\n",
      "Recall of Random Forest with Gradient Boost Selected Features: 0.5\n",
      "F1-Score of Random Forest with Gradient Boost Selected Features: 0.31999999999999995\n"
     ]
    }
   ],
   "source": [
    "#workflow for doing Random Forest\n",
    "#MODIFY THIS - TRY TO NOT MODIFY FUNCTIONS\n",
    "#we are trying this with the modified feature list from gradient boositng\n",
    "train, test = TrainTestSplit(df_gb_select)\n",
    "folds = MakeKFolds(train)\n",
    "g = rf.MakeTuningGrid(min_max = 10, frac_min = 0.7, depth_min=4, depth_max=8, n = 100, subs_min=0.7, subs_max=0.9)\n",
    "best_params = TuneForest(folds, g)\n",
    "SaveParams(best_params, \"params_rf_gb.txt\")\n",
    "final_forest_gb = rf.BuildRandomForest(train, trees = best_params[4], \n",
    "                                 subset_frac = best_params[3], min = best_params[0],\n",
    "                                 frac = best_params[1], maxDepth = best_params[2])\n",
    "preds_gb = rf.ForestPredict(final_forest_gb, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, \"Random Forest with Gradient Boost Selected Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 0.5961538461538461\n",
      "Precision of Random Forest: 0.23529411764705882\n",
      "Recall of Random Forest: 0.3333333333333333\n",
      "F1-Score of Random Forest: 0.27586206896551724\n"
     ]
    }
   ],
   "source": [
    "#randomforest workflow\n",
    "#with default parameters\n",
    "train, test = TrainTestSplit(df)\n",
    "f = rf.BuildRandomForest(train, 50)\n",
    "preds = rf.ForestPredict(f, test)\n",
    "tp, fp, tn, fn = dt.GetConfusionMatrix(test, preds)\n",
    "PrintMetrics(tp, fp, tn, fn, name = \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save my session!\n",
    "dill.dump_session(\"dtrf_models.db\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
